{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-lingual Transfer Learning for NER Tagging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data Danish Data in `Conll` format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datasets:\n",
    "- `danish_train.conll`\n",
    "- `danish_test.conll`\n",
    "- `danish dev.conll`\n",
    "\n",
    "format:\n",
    "- `danish_word [tab] BIO_tag-NER_tag`\n",
    "- `\\n` between sentences\n",
    "- entity-types:\n",
    "    - `LOC`\n",
    "    - `MISC`\n",
    "    - `ORG`\n",
    "    - `PER`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import spacy \n",
    "from spacy.util import minibatch, compounding\n",
    "from random import shuffle, seed\n",
    "import numpy as np\n",
    "import torch\n",
    "from spacy.training import Example\n",
    "from copy import deepcopy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Berlingske', 'B-ORG')]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define function for reading data\n",
    "def read_data(file):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        file (_type_): ner dataset in conll format\n",
    "    Output:\n",
    "        a list of sentences\n",
    "        each sentence made up of a list of tuples with (token,bio_tag)\n",
    "    \"\"\"\n",
    "\n",
    "    data = []\n",
    "    sentence = []\n",
    "    for line in file:\n",
    "        if line.strip() == \"\":\n",
    "            data.append(sentence)\n",
    "            sentence = []\n",
    "        else:\n",
    "            sentence.append(tuple(line.strip().split(\"\\t\")))\n",
    "    if len(data) == 0:\n",
    "        data.append(sentence)\n",
    "    return data\n",
    "            \n",
    "\n",
    "import io\n",
    "\n",
    "\n",
    "#test for reading a file with a single line\n",
    "test_string = \"Berlingske\\tB-ORG\"\n",
    "assert read_data(io.StringIO(test_string)) == [[(\"Berlingske\",\"B-ORG\")]]\n",
    "\n",
    "\n",
    "#test for reading an empty file\n",
    "assert read_data(io.StringIO(\"\"))==[[]]\n",
    "\n",
    "\n",
    "#test for reading files with line breaker at the end\n",
    "read_data(io.StringIO(test_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Data into spaCy format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "danish_train = read_data(open(\"data/danish-train.conll\"))\n",
    "danish_test = read_data(open(\"data/danish-test.conll\"))\n",
    "danish_dev = read_data(open(\"data/danish-dev.conll\"))\n",
    "\n",
    "\n",
    "def get_spacy_ner_data(data):\n",
    "    spacy_ner_data = []\n",
    "\n",
    "    for sent in data:\n",
    "        ind = 0\n",
    "        entities = []\n",
    "        full_sentence = \" \".join([pair[0] for pair in sent])\n",
    "        for token, tag in sent:\n",
    "            iob_tag = tag[0]\n",
    "            if iob_tag == \"B\":\n",
    "                entity = (ind, ind + len(token),tag[2:])\n",
    "                entities.append(entity)\n",
    "            elif iob_tag == \"I\":\n",
    "                start,end,label = entities.pop()\n",
    "                entity = (start, end + len(token) + 1,label)\n",
    "                entities.append(entity)\n",
    "            ind += (len(token) + 1)\n",
    "        spacy_ner_data.append((full_sentence,{\"entities\":entities}))\n",
    " \n",
    "    return spacy_ner_data\n",
    "\n",
    "\n",
    "\n",
    "danish_train_spacy = get_spacy_ner_data(danish_train)\n",
    "danish_test_spacy = get_spacy_ner_data(danish_test)\n",
    "danish_dev_spacy = get_spacy_ner_data(danish_dev)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Evaluation System with `Recall`, `Precision` and `f-score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(system_spacy_data, gold_spacy_data):\n",
    "    n_sys = 0\n",
    "    n_gold = 0\n",
    "    n_correct = 0\n",
    "    for sys_sent, gold_sent in zip(system_spacy_data,gold_spacy_data):\n",
    "        n_sys += len(sys_sent[1][\"entities\"])\n",
    "        n_gold += len(gold_sent[1][\"entities\"])\n",
    "        set(sys_sent[1][\"entities\"])\n",
    "        set(gold_sent[1][\"entities\"])\n",
    "        n_correct += len(set(sys_sent[1][\"entities\"]).intersection(set(gold_sent[1][\"entities\"])))\n",
    "    precision = n_correct / n_sys * 100\n",
    "    recall = n_correct / n_gold * 100\n",
    "    fscore = 0 if n_correct == 0 else 2 * precision*recall / (precision+recall)\n",
    "    return precision,recall,fscore\n",
    "\n",
    "sys_data = [(\"word1 word2 word3 word4\",{\"entities\":[(0,5,\"PER\"),(12,17,\"LOC\")]}),\n",
    "            (\"word1 word2 word3 word4\",{\"entities\":[(6,11,\"ORG\")]})]\n",
    "\n",
    "gold_data = [(\"word1 word2 word3 word4\",{\"entities\":[(0,6,\"PER\"),(12,17,\"LOC\")]}),\n",
    "             (\"word1 word2 word3 word4\",{\"entities\":[]})]\n",
    "\n",
    "precision, recall, fscore = evaluate(sys_data,gold_data)\n",
    "\n",
    "assert precision == 1.0/3 * 100\n",
    "assert recall == 1.0/2 * 100\n",
    "assert fscore == 2*1.0/3*1.0/2 / (1.0/3 + 1.0/2) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the `NER_MODEL`\n",
    "- Define `init_model` function:\n",
    "    - `ner_annotated_data` in `spaCy` format\n",
    "    - `language_code`: either `en` or `da`\n",
    "\n",
    "- Changes needed to make for `spaCy-3.0`\n",
    "    - create blank `text-preprocessing` pipeline with `spacy.blank` called `model`\n",
    "    - add `ner` submodel to that pipeline (`model`) using `add_pipe()`\n",
    "    - include all entity types appearing in `spacy_train_data` using `add_label`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(spacy_train_data, language):\n",
    "    #create a blank spacy model with specified language\n",
    "    model = spacy.blank(language)\n",
    "\n",
    "    #setting seed for reproducibility\n",
    "    seed(0)\n",
    "    np.random.seed(0)\n",
    "    spacy.util.fix_random_seed(0)\n",
    "    torch.manual_seed(0)\n",
    "    \n",
    "    ner = model.add_pipe(\"ner\")\n",
    "\n",
    "    #add all ne types in training data to ner component\n",
    "    for _, annotation in spacy_train_data:\n",
    "        for entity in annotation.get(\"entities\"):\n",
    "            ner.add_label(entity[2])\n",
    "\n",
    "    # Make sure we're only training the NER component of the pipeline\n",
    "    pipe_exceptions = [\"ner\"]\n",
    "    other_pipes = [pipe for pipe in model.pipe_names if pipe not in pipe_exceptions]\n",
    "\n",
    "    # Start training so that we can use the model to annotate data\n",
    "    model.disable_pipes(*other_pipes)\n",
    "    optimizer = model.begin_training()\n",
    "    return model, optimizer\n",
    "\n",
    "danish_untrained_model, _ = init_model(danish_train_spacy,\"da\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define an `Annotation Function` to make inference with `NER_MODEL` (to be trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate(spacy_data,model):\n",
    "    result = []\n",
    "\n",
    "    for sent, _ in spacy_data:\n",
    "        doc = model(sent)\n",
    "        entities = [(ent.start_char,ent.end_char,ent.label_) for ent in doc.ents]\n",
    "        result.append((sent,{\"entities\":entities}))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the `NER MODEL` initialized in the previous step\n",
    "\n",
    "[LINK TO EXAMPLE CODE WALK THRU](https://github.com/explosion/spaCy/blob/v2.x/examples/training/train_ner.py)\n",
    "\n",
    "\n",
    "Steps:\n",
    "- Convert `sent,annotation` tuples into `Example` objects\n",
    "- Shuffle the data at the start of each epoch\n",
    "- Batch up data with `spacy.util.minibatch`:\n",
    "    - fixed size\n",
    "    - varying size: provide a generator to `size` arguement\n",
    "    - compounding size of batches with `compounding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(spacy_train_data, spacy_dev_data, epochs, language):\n",
    "    #Initialize model and optimizer\n",
    "    model, optimizer = init_model(spacy_train_data,language)\n",
    "\n",
    "    spacy_train_data = deepcopy(spacy_train_data)\n",
    "\n",
    "    for itn in range(epochs):\n",
    "        losses = {}\n",
    "        random.shuffle(spacy_train_data)\n",
    "        batches = minibatch(spacy_train_data,size=5)\n",
    "\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            examples = []\n",
    "            # Update the model with every iteration\n",
    "            for i in range(len(texts)):\n",
    "                doc = model.make_doc(texts[i])\n",
    "                examples.append(Example.from_dict(doc, annotations[i]))\n",
    "\n",
    "            model.update(examples,\n",
    "                         losses=losses, #update the losses in-place\n",
    "                         drop=0.1)\n",
    "                \n",
    "        print(\"Losses\", losses)\n",
    "        \n",
    "        # Evaluate model\n",
    "        print(\"Loss for epoch %u: %.4f\" % (itn+1, losses[\"ner\"]))\n",
    "        spacy_dev_sys = annotate(spacy_dev_data, model)\n",
    "        p, r, f = evaluate(spacy_dev_sys,spacy_dev_data)\n",
    "        print(\"  PRECISION: %.2f%%, RECALL: %.2f%%, F-SCORE: %.2f%%\" % (p,r,f))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': np.float32(867.636)}\n",
      "Loss for epoch 1: 867.6360\n",
      "  PRECISION: 0.00%, RECALL: 0.00%, F-SCORE: 0.00%\n",
      "Losses {'ner': np.float32(274.55267)}\n",
      "Loss for epoch 2: 274.5527\n",
      "  PRECISION: 43.66%, RECALL: 35.73%, F-SCORE: 39.30%\n",
      "Losses {'ner': np.float32(119.764015)}\n",
      "Loss for epoch 3: 119.7640\n",
      "  PRECISION: 42.68%, RECALL: 39.48%, F-SCORE: 41.02%\n",
      "Losses {'ner': np.float32(137.19289)}\n",
      "Loss for epoch 4: 137.1929\n",
      "  PRECISION: 44.06%, RECALL: 43.80%, F-SCORE: 43.93%\n",
      "Losses {'ner': np.float32(112.6825)}\n",
      "Loss for epoch 5: 112.6825\n",
      "  PRECISION: 46.44%, RECALL: 39.48%, F-SCORE: 42.68%\n",
      "Losses {'ner': np.float32(53.071445)}\n",
      "Loss for epoch 6: 53.0714\n",
      "  PRECISION: 46.05%, RECALL: 40.35%, F-SCORE: 43.01%\n",
      "Losses {'ner': np.float32(52.874985)}\n",
      "Loss for epoch 7: 52.8750\n",
      "  PRECISION: 44.85%, RECALL: 35.16%, F-SCORE: 39.42%\n",
      "Losses {'ner': np.float32(38.8294)}\n",
      "Loss for epoch 8: 38.8294\n",
      "  PRECISION: 49.44%, RECALL: 38.33%, F-SCORE: 43.18%\n",
      "Losses {'ner': np.float32(25.486406)}\n",
      "Loss for epoch 9: 25.4864\n",
      "  PRECISION: 40.29%, RECALL: 40.06%, F-SCORE: 40.17%\n",
      "Losses {'ner': np.float32(56.02507)}\n",
      "Loss for epoch 10: 56.0251\n",
      "  PRECISION: 44.51%, RECALL: 44.38%, F-SCORE: 44.44%\n",
      "Losses {'ner': np.float32(18.223597)}\n",
      "Loss for epoch 11: 18.2236\n",
      "  PRECISION: 46.23%, RECALL: 40.63%, F-SCORE: 43.25%\n",
      "Losses {'ner': np.float32(7.561675)}\n",
      "Loss for epoch 12: 7.5617\n",
      "  PRECISION: 46.32%, RECALL: 43.52%, F-SCORE: 44.87%\n",
      "Losses {'ner': np.float32(10.262288)}\n",
      "Loss for epoch 13: 10.2623\n",
      "  PRECISION: 48.61%, RECALL: 40.35%, F-SCORE: 44.09%\n",
      "Losses {'ner': np.float32(20.457106)}\n",
      "Loss for epoch 14: 20.4571\n",
      "  PRECISION: 44.41%, RECALL: 36.60%, F-SCORE: 40.13%\n",
      "Losses {'ner': np.float32(9.075884)}\n",
      "Loss for epoch 15: 9.0759\n",
      "  PRECISION: 45.95%, RECALL: 39.19%, F-SCORE: 42.30%\n",
      "Losses {'ner': np.float32(4.016085)}\n",
      "Loss for epoch 16: 4.0161\n",
      "  PRECISION: 42.37%, RECALL: 39.19%, F-SCORE: 40.72%\n",
      "Losses {'ner': np.float32(5.2911897)}\n",
      "Loss for epoch 17: 5.2912\n",
      "  PRECISION: 47.18%, RECALL: 38.62%, F-SCORE: 42.47%\n",
      "Losses {'ner': np.float32(9.722229)}\n",
      "Loss for epoch 18: 9.7222\n",
      "  PRECISION: 45.94%, RECALL: 37.46%, F-SCORE: 41.27%\n",
      "Losses {'ner': np.float32(5.8788214)}\n",
      "Loss for epoch 19: 5.8788\n",
      "  PRECISION: 44.26%, RECALL: 37.75%, F-SCORE: 40.75%\n",
      "Losses {'ner': np.float32(8.381658)}\n",
      "Loss for epoch 20: 8.3817\n",
      "  PRECISION: 46.05%, RECALL: 40.35%, F-SCORE: 43.01%\n",
      "\n",
      "Evaluating model on development set:\n",
      "  PRECISION: 46.05%, RECALL: 40.35%, F-SCORE: 43.01%\n"
     ]
    }
   ],
   "source": [
    "danish_model = train(danish_train_spacy,danish_dev_spacy,20,\"da\")\n",
    "print()\n",
    "print(\"Evaluating model on development set:\")\n",
    "\n",
    "danish_dev_spacy_sys = annotate(danish_dev_spacy, danish_model)\n",
    "\n",
    "p, r, f = evaluate(danish_dev_spacy_sys,danish_dev_spacy)\n",
    "print(\"  PRECISION: %.2f%%, RECALL: %.2f%%, F-SCORE: %.2f%%\" % (p,r,f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainining with `Pocket Learning` (Documenting the best-performing model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(spacy_train_data, spacy_dev_data, epochs,language):\n",
    "    # Initialize model and get optimizer\n",
    "    model, optimizer = init_model(spacy_train_data,language)\n",
    "    \n",
    "    # Make sure we don't permute the original training data.\n",
    "    spacy_train_data = deepcopy(spacy_train_data)\n",
    "    best_f = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for itn in range(epochs):\n",
    "        losses = {}\n",
    "        random.shuffle(spacy_train_data)\n",
    "        batches = minibatch(spacy_train_data,size=5)\n",
    "\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            example = []\n",
    "            # Update the model with every iteration\n",
    "            for i in range(len(texts)):\n",
    "                doc = model.make_doc(texts[i])\n",
    "                example.append(Example.from_dict(doc, annotations[i]))\n",
    "\n",
    "            model.update(example,\n",
    "                         losses=losses, #update the losses in-place\n",
    "                         drop=0.1)\n",
    "        print(\"Loss for epoch %u: %.4f\" % (itn+1, losses[\"ner\"]))\n",
    "        spacy_dev_sys = annotate(spacy_dev_data, model)\n",
    "        p, r, f = evaluate(spacy_dev_sys,spacy_dev_data)\n",
    "        print(\"  PRECISION: %.2f%%, RECALL: %.2f%%, F-SCORE: %.2f%%\" % (p,r,f))\n",
    "        if f > best_f:\n",
    "            best_f = f\n",
    "            best_model = deepcopy(model)\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1: 867.6360\n",
      "  PRECISION: 0.00%, RECALL: 0.00%, F-SCORE: 0.00%\n",
      "Loss for epoch 2: 274.5527\n",
      "  PRECISION: 43.66%, RECALL: 35.73%, F-SCORE: 39.30%\n",
      "Loss for epoch 3: 119.7640\n",
      "  PRECISION: 42.68%, RECALL: 39.48%, F-SCORE: 41.02%\n",
      "Loss for epoch 4: 137.1929\n",
      "  PRECISION: 44.06%, RECALL: 43.80%, F-SCORE: 43.93%\n",
      "Loss for epoch 5: 112.6825\n",
      "  PRECISION: 46.44%, RECALL: 39.48%, F-SCORE: 42.68%\n",
      "Loss for epoch 6: 53.0714\n",
      "  PRECISION: 46.05%, RECALL: 40.35%, F-SCORE: 43.01%\n",
      "Loss for epoch 7: 52.8750\n",
      "  PRECISION: 44.85%, RECALL: 35.16%, F-SCORE: 39.42%\n",
      "Loss for epoch 8: 38.8294\n",
      "  PRECISION: 49.44%, RECALL: 38.33%, F-SCORE: 43.18%\n",
      "Loss for epoch 9: 25.4864\n",
      "  PRECISION: 40.29%, RECALL: 40.06%, F-SCORE: 40.17%\n",
      "Loss for epoch 10: 56.0251\n",
      "  PRECISION: 44.51%, RECALL: 44.38%, F-SCORE: 44.44%\n",
      "Loss for epoch 11: 18.2236\n",
      "  PRECISION: 46.23%, RECALL: 40.63%, F-SCORE: 43.25%\n",
      "Loss for epoch 12: 7.5617\n",
      "  PRECISION: 46.32%, RECALL: 43.52%, F-SCORE: 44.87%\n",
      "Loss for epoch 13: 10.2623\n",
      "  PRECISION: 48.61%, RECALL: 40.35%, F-SCORE: 44.09%\n",
      "Loss for epoch 14: 20.4571\n",
      "  PRECISION: 44.41%, RECALL: 36.60%, F-SCORE: 40.13%\n",
      "Loss for epoch 15: 9.0759\n",
      "  PRECISION: 45.95%, RECALL: 39.19%, F-SCORE: 42.30%\n",
      "Loss for epoch 16: 4.0161\n",
      "  PRECISION: 42.37%, RECALL: 39.19%, F-SCORE: 40.72%\n",
      "Loss for epoch 17: 5.2912\n",
      "  PRECISION: 47.18%, RECALL: 38.62%, F-SCORE: 42.47%\n",
      "Loss for epoch 18: 9.7222\n",
      "  PRECISION: 45.94%, RECALL: 37.46%, F-SCORE: 41.27%\n",
      "Loss for epoch 19: 5.8788\n",
      "  PRECISION: 44.26%, RECALL: 37.75%, F-SCORE: 40.75%\n",
      "Loss for epoch 20: 8.3817\n",
      "  PRECISION: 46.05%, RECALL: 40.35%, F-SCORE: 43.01%\n",
      "\n",
      "Evaluating model on development set:\n",
      "PRECISION: 46.32%, RECALL: 43.52%, F-SCORE: 44.87%\n"
     ]
    }
   ],
   "source": [
    "danish_model = train(danish_train_spacy,danish_dev_spacy,20,\"da\")\n",
    "print()\n",
    "print(\"Evaluating model on development set:\")\n",
    "danish_dev_spacy_sys = annotate(danish_dev_spacy, danish_model)\n",
    "p, r, f = evaluate(danish_dev_spacy_sys,danish_dev_spacy)\n",
    "print(\"PRECISION: %.2f%%, RECALL: %.2f%%, F-SCORE: %.2f%%\" % (p,r,f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add pretrained bilingual embeddings during initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.vocab import Vocab\n",
    "\n",
    "def init_model(spacy_train_data, language):\n",
    "    model = spacy.blank(language)#config={\"paths\":{\"vectors\":\"data/vocab\"}})\n",
    "\n",
    "    seed(0)\n",
    "    np.random.seed(0)\n",
    "    spacy.util.fix_random_seed(0)\n",
    "    torch.manual_seed(0)\n",
    "    \n",
    "    \n",
    "    #load pretrained bilingual embeddings\n",
    "    model.vocab.from_disk(\"data/vocab\")\n",
    "\n",
    "    #add config argument to add.pipe to ensure the actual usage of embeddings   \n",
    "    ner = model.add_pipe(\"ner\",\n",
    "                         config={\"model\":{\"tok2vec\":{\"pretrained_vectors\":True}}})\n",
    "\n",
    "\n",
    "    #add all entity types to ner component\n",
    "    for _, annotations in spacy_train_data:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "    # Make sure we're only training the NER component of the pipeline\n",
    "    pipe_exceptions = [\"ner\"]\n",
    "    other_pipes = [pipe for pipe in model.pipe_names if pipe not in pipe_exceptions]\n",
    "\n",
    "    # Start training so that we can use the model to annotate data\n",
    "    model.disable_pipes(*other_pipes)\n",
    "    optimizer = model.begin_training()\n",
    "\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1: 910.9559\n",
      "  PRECISION: 39.84%, RECALL: 14.12%, F-SCORE: 20.85%\n",
      "Loss for epoch 2: 181.7382\n",
      "  PRECISION: 44.98%, RECALL: 37.46%, F-SCORE: 40.88%\n",
      "Loss for epoch 3: 117.4945\n",
      "  PRECISION: 47.73%, RECALL: 42.36%, F-SCORE: 44.89%\n",
      "Loss for epoch 4: 98.7817\n",
      "  PRECISION: 50.81%, RECALL: 45.24%, F-SCORE: 47.87%\n",
      "Loss for epoch 5: 61.0618\n",
      "  PRECISION: 47.38%, RECALL: 49.57%, F-SCORE: 48.45%\n",
      "Loss for epoch 6: 42.8465\n",
      "  PRECISION: 46.51%, RECALL: 49.86%, F-SCORE: 48.12%\n",
      "Loss for epoch 7: 29.6811\n",
      "  PRECISION: 51.34%, RECALL: 44.09%, F-SCORE: 47.44%\n",
      "Loss for epoch 8: 40.5796\n",
      "  PRECISION: 48.80%, RECALL: 46.97%, F-SCORE: 47.87%\n",
      "Loss for epoch 9: 27.2266\n",
      "  PRECISION: 51.62%, RECALL: 45.82%, F-SCORE: 48.55%\n",
      "Loss for epoch 10: 91.1609\n",
      "  PRECISION: 47.80%, RECALL: 43.80%, F-SCORE: 45.71%\n",
      "Loss for epoch 11: 30.1131\n",
      "  PRECISION: 50.75%, RECALL: 48.70%, F-SCORE: 49.71%\n",
      "Loss for epoch 12: 14.3707\n",
      "  PRECISION: 56.47%, RECALL: 45.24%, F-SCORE: 50.24%\n",
      "Loss for epoch 13: 7.8904\n",
      "  PRECISION: 51.72%, RECALL: 47.55%, F-SCORE: 49.55%\n",
      "Loss for epoch 14: 8.5159\n",
      "  PRECISION: 50.00%, RECALL: 46.69%, F-SCORE: 48.29%\n",
      "Loss for epoch 15: 3.6263\n",
      "  PRECISION: 53.11%, RECALL: 49.28%, F-SCORE: 51.12%\n",
      "Loss for epoch 16: 10.3870\n",
      "  PRECISION: 53.29%, RECALL: 48.99%, F-SCORE: 51.05%\n",
      "Loss for epoch 17: 5.1501\n",
      "  PRECISION: 57.00%, RECALL: 50.43%, F-SCORE: 53.52%\n",
      "Loss for epoch 18: 11.0402\n",
      "  PRECISION: 53.56%, RECALL: 49.86%, F-SCORE: 51.64%\n",
      "Loss for epoch 19: 2.4976\n",
      "  PRECISION: 50.47%, RECALL: 46.40%, F-SCORE: 48.35%\n",
      "Loss for epoch 20: 5.4505\n",
      "  PRECISION: 53.65%, RECALL: 48.70%, F-SCORE: 51.06%\n",
      "\n",
      "Evaluating model on development set:\n",
      "  PRECISION: 57.00%, RECALL: 50.43%, F-SCORE: 53.52%\n"
     ]
    }
   ],
   "source": [
    "danish_model = train(danish_train_spacy,danish_dev_spacy,20,\"da\")\n",
    "print()\n",
    "print(\"Evaluating model on development set:\")\n",
    "danish_dev_spacy_sys = annotate(danish_dev_spacy, danish_model)\n",
    "p, r, f = evaluate(danish_dev_spacy_sys,danish_dev_spacy)\n",
    "print(\"  PRECISION: %.2f%%, RECALL: %.2f%%, F-SCORE: %.2f%%\" % (p,r,f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer-learning: \n",
    "Train an English NER System and fine-tune on Danish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1: 11073.0596\n",
      "  PRECISION: 87.16%, RECALL: 86.00%, F-SCORE: 86.57%\n",
      "Loss for epoch 2: 5694.5972\n",
      "  PRECISION: 86.91%, RECALL: 87.39%, F-SCORE: 87.15%\n",
      "Loss for epoch 3: 4177.0112\n",
      "  PRECISION: 87.80%, RECALL: 87.78%, F-SCORE: 87.79%\n",
      "Loss for epoch 4: 3278.9580\n",
      "  PRECISION: 90.00%, RECALL: 88.93%, F-SCORE: 89.46%\n",
      "Loss for epoch 5: 2964.8284\n",
      "  PRECISION: 90.23%, RECALL: 89.38%, F-SCORE: 89.80%\n"
     ]
    }
   ],
   "source": [
    "#Load english training data\n",
    "english_train = read_data(open(path.join(\"data\",\"english-train.conll\")))\n",
    "english_dev = read_data(open(path.join(\"data\",\"english-dev.conll\")))\n",
    "\n",
    "#Convert data into spaCy format\n",
    "english_spacy_train = get_spacy_ner_data(english_train)\n",
    "english_spacy_dev = get_spacy_ner_data(english_dev)\n",
    "\n",
    "#Train english NER model\n",
    "english_model = train(english_spacy_train,english_spacy_dev,5,\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1: 217.5671\n",
      "  PRECISION: 56.18%, RECALL: 55.04%, F-SCORE: 55.60%\n",
      "Loss for epoch 2: 93.6002\n",
      "  PRECISION: 58.76%, RECALL: 59.94%, F-SCORE: 59.34%\n",
      "Loss for epoch 3: 52.7189\n",
      "  PRECISION: 62.99%, RECALL: 60.81%, F-SCORE: 61.88%\n",
      "Loss for epoch 4: 31.0359\n",
      "  PRECISION: 62.73%, RECALL: 59.65%, F-SCORE: 61.15%\n",
      "Loss for epoch 5: 20.0590\n",
      "  PRECISION: 63.98%, RECALL: 59.37%, F-SCORE: 61.58%\n",
      "Loss for epoch 6: 14.4064\n",
      "  PRECISION: 60.59%, RECALL: 59.37%, F-SCORE: 59.97%\n",
      "Loss for epoch 7: 4.3865\n",
      "  PRECISION: 61.77%, RECALL: 58.21%, F-SCORE: 59.94%\n",
      "Loss for epoch 8: 4.5780\n",
      "  PRECISION: 61.89%, RECALL: 58.50%, F-SCORE: 60.15%\n",
      "Loss for epoch 9: 1.9884\n",
      "  PRECISION: 59.47%, RECALL: 57.93%, F-SCORE: 58.69%\n",
      "Loss for epoch 10: 1.9681\n",
      "  PRECISION: 59.59%, RECALL: 59.08%, F-SCORE: 59.33%\n",
      "Loss for epoch 11: 6.7378\n",
      "  PRECISION: 60.00%, RECALL: 58.79%, F-SCORE: 59.39%\n",
      "Loss for epoch 12: 7.9623\n",
      "  PRECISION: 59.42%, RECALL: 59.08%, F-SCORE: 59.25%\n",
      "Loss for epoch 13: 3.0925\n",
      "  PRECISION: 60.29%, RECALL: 59.08%, F-SCORE: 59.68%\n",
      "Loss for epoch 14: 2.1386\n",
      "  PRECISION: 60.65%, RECALL: 59.08%, F-SCORE: 59.85%\n",
      "Loss for epoch 15: 7.4510\n",
      "  PRECISION: 61.16%, RECALL: 60.81%, F-SCORE: 60.98%\n",
      "Loss for epoch 16: 4.6200\n",
      "  PRECISION: 60.98%, RECALL: 60.81%, F-SCORE: 60.89%\n",
      "Loss for epoch 17: 3.0888\n",
      "  PRECISION: 61.03%, RECALL: 61.38%, F-SCORE: 61.21%\n",
      "Loss for epoch 18: 1.9261\n",
      "  PRECISION: 61.06%, RECALL: 59.65%, F-SCORE: 60.35%\n",
      "Loss for epoch 19: 12.6948\n",
      "  PRECISION: 60.06%, RECALL: 59.37%, F-SCORE: 59.71%\n",
      "Loss for epoch 20: 1.8707\n",
      "  PRECISION: 60.41%, RECALL: 59.37%, F-SCORE: 59.88%\n",
      "Evaluating basic Danish model on test set:\n",
      "  PRECISION: 59.33%, RECALL: 49.74%, F-SCORE: 54.11%\n",
      "\n",
      "Evaluating basic transfer model on test set:\n",
      "  PRECISION: 62.04%, RECALL: 60.77%, F-SCORE: 61.40%\n"
     ]
    }
   ],
   "source": [
    "def retrain(spacy_train_data, spacy_dev_data, epochs,model):\n",
    "    # Make sure we don't modify the original training data.\n",
    "    spacy_train_data = deepcopy(spacy_train_data)\n",
    "    \n",
    "    model = deepcopy(model)\n",
    "    \n",
    "    #copying code from train below\n",
    "    for itn in range(epochs):\n",
    "        losses = {}\n",
    "        random.shuffle(spacy_train_data)\n",
    "        batches = minibatch(spacy_train_data,size=5)\n",
    "\n",
    "        for i,batch in enumerate(batches):\n",
    "            texts, annotations = zip(*batch)\n",
    "            example = []\n",
    "            # Update the model with every iteration\n",
    "            for j in range(len(texts)):\n",
    "                doc = model.make_doc(texts[j])\n",
    "                example.append(Example.from_dict(doc, annotations[j]))\n",
    "\n",
    "            model.update(example,\n",
    "                         losses=losses,\n",
    "                         drop=0.1)\n",
    "        \n",
    "        \n",
    "        # Evaluate model\n",
    "        print(\"Loss for epoch %u: %.4f\" % (itn+1, losses[\"ner\"]))\n",
    "        spacy_dev_sys = annotate(spacy_dev_data, model)\n",
    "        p, r, f = evaluate(spacy_dev_sys,spacy_dev_data)\n",
    "        print(\"  PRECISION: %.2f%%, RECALL: %.2f%%, F-SCORE: %.2f%%\" % (p,r,f))\n",
    "    return model\n",
    "\n",
    "transfer_model = retrain(danish_train_spacy, danish_dev_spacy, 20,english_model)\n",
    "\n",
    "print(\"Evaluating basic Danish model on test set:\")\n",
    "danish_spacy_test_sys_basic = annotate(danish_test_spacy, danish_model)\n",
    "p, r, f = evaluate(danish_spacy_test_sys_basic,danish_test_spacy)\n",
    "print(\"  PRECISION: %.2f%%, RECALL: %.2f%%, F-SCORE: %.2f%%\" % (p,r,f))\n",
    "print()\n",
    "\n",
    "print(\"Evaluating basic transfer model on test set:\")\n",
    "danish_spacy_test_sys_transfer = annotate(danish_test_spacy, transfer_model)\n",
    "p, r, f = evaluate(danish_spacy_test_sys_transfer,danish_test_spacy)\n",
    "print(\"  PRECISION: %.2f%%, RECALL: %.2f%%, F-SCORE: %.2f%%\" % (p,r,f))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computational-linguistics-22J8LE1G",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
